# MS MARCO Passage Ranking Example

In this example, we use Asyncval to validate dense retreiver ckeckpoints generated by [Tevatron](https://github.com/texttron/tevatron) training toolkit.

## Start Tevatron Training
First, follow the instruction in this tevatron [example](https://github.com/texttron/tevatron/tree/main/examples/msmarco-passage-ranking) to get MS MARCO data and start training. You don't need to do the encoding and search steps.

## Sample Corpus Subset

Conducting retrieval validation against the full corpus is very slow. To speed up validation time for each checkpoint without loss validation accuracy, we can fisrt sample a subset of corpus based on a given run file and the qrel file which provides gold (relevant) passages for each query in the validation set.

Frist, to have a run file, you can use [Pyserini](https://github.com/castorini/pyserini) IR toolkit to get a MS MARCO dev query run file. In this example we use [TCT-ColBERTv2](https://github.com/castorini/pyserini/blob/master/docs/experiments-distilbert_tasb.md) as our base DR model to generate the run file.

After to get the run file, run the following command to create the corpus subset:

```
python3 -m asyncval.splitter \
--candidate_dir ./marco/bert/corpus/ \
--run_file path/to/run.msmarco-passage.distilbert-dot-tas_b-b256.bf.tsv \
--qrel_file path/to/qrels.dev.small.tsv \
--output_dir ./marco/bert/corpus_tctv2_subset_top10/ \
--depth 10 \
--num_splits 5 \
--cache_dir cache
```
(Note: downloaded the `qrels.dev.small.tsv` from MS MARCO offical [GitHub](https://github.com/microsoft/MSMARCO-Passage-Ranking))


## Start Asyncval Validation

Once you kick off tevatron trainig and get corpus subset prepared, you can directly start asyncval validation with the following command:

```
python -m asyncval \
--query_file ./marco/bert/query/dev.query.json \
--candidate_dir ./marco/bert/corpus_tctv2_subset_top10 \
--ckpts_dir ../retriever_model \
--tokenizer_name_or_path bert-base-uncased \
--qrel_file path/to/qrels.dev.small.tsv \
--metrics RR@10 nDCG@10 \
--output_dir ./tevatron_retriever_model \
--report_to tensorboard \
--logging_dir ./logs/tevatron_retriever_model
--depth 10 \
--per_device_eval_batch_size 64 \
--fp16
```

The following are the retrieval validation results on tensorboard:
![results.png](results.png)
